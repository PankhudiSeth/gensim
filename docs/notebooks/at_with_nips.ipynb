{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "// Run for table of contents.\n",
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n",
       "\n",
       "// https://github.com/kmahelona/ipython_notebook_goodies"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// Run for table of contents.\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n",
    "\n",
    "// https://github.com/kmahelona/ipython_notebook_goodies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests with NIPS data\n",
    "\n",
    "<h2 id=\"tocheading\">Table of Contents</h2>\n",
    "<div id=\"toc\"></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from imp import reload\n",
    "from pprint import pprint\n",
    "from random import sample\n",
    "import bokeh\n",
    "import line_profiler\n",
    "\n",
    "import logging\n",
    "\n",
    "from gensim.models import AuthorTopicModel\n",
    "from gensim.models import atmodel\n",
    "from gensim.models import AuthorTopicModelOld\n",
    "from gensim.models import atmodelold\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import ldamodel\n",
    "\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configure logging.\n",
    "\n",
    "log_dir = '../../../log_files/log.log'  # On my own machine.\n",
    "#log_dir = '../../../../log_files/log.log'  # On Hetzner\n",
    "\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename=log_dir, mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Folder containing all NIPS papers.\n",
    "data_dir = '../../../../data/nipstxt/'  # On my own machine.\n",
    "#data_dir = '../../../nipstxt/'  # On Hetzner.\n",
    "\n",
    "# Folders containin individual NIPS papers.\n",
    "#yrs = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "yrs = ['00', '01', '02']\n",
    "dirs = ['nips' + yr for yr in yrs]\n",
    "\n",
    "# Get all document texts and their corresponding IDs.\n",
    "docs = []\n",
    "doc_ids = []\n",
    "for yr_dir in dirs:\n",
    "    files = os.listdir(data_dir + yr_dir)  # List of filenames.\n",
    "    for filen in files:\n",
    "        # Get document ID.\n",
    "        (idx1, idx2) = re.search('[0-9]+', filen).span()  # Matches the indexes of the start end end of the ID.\n",
    "        doc_ids.append(yr_dir[4:] + '_' + str(int(filen[idx1:idx2])))\n",
    "        \n",
    "        # Read document text.\n",
    "        # Note: ignoring characters that cause encoding errors.\n",
    "        with open(data_dir + yr_dir + '/' + filen, errors='ignore', encoding='utf-8') as fid:\n",
    "            txt = fid.read()\n",
    "        docs.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = [data_dir + 'idx/a' + yr + '.txt' for yr in yrs]  # Using the years defined in previous cell.\n",
    "\n",
    "# Get all author names and their corresponding document IDs.\n",
    "author2id = dict()\n",
    "author2doc = dict()\n",
    "i = 0\n",
    "for yr in yrs:\n",
    "    filename = data_dir + 'idx/a' + yr + '.txt'\n",
    "    for line in open(filename, errors='ignore', encoding='utf-8'):\n",
    "        contents = re.split(',', line)\n",
    "        author_name = (contents[1] + contents[0]).strip()\n",
    "        ids = [c.strip() for c in contents[2:]]\n",
    "        if not author2id.get(author_name):\n",
    "            author2id[author_name] = i\n",
    "            author2doc[i] = []\n",
    "            i += 1\n",
    "        \n",
    "        author_id = author2id[author_name]\n",
    "        author2doc[author_id].extend([yr + '_' + id for id in ids])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a mapping from author ID to author name.\n",
    "id2author = dict(zip(author2id.values(), author2id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use an integer ID in author2doc, instead of the IDs provided in the NIPS dataset.\n",
    "\n",
    "# Mapping from ID of document in NIPS datast, to an integer ID.\n",
    "doc_id_dict = dict(zip(doc_ids, range(len(doc_ids))))\n",
    "\n",
    "for a, a_doc_ids in author2doc.items():\n",
    "    for i, doc_id in enumerate(a_doc_ids):\n",
    "        author2doc[a][i] = doc_id_dict[doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a mapping from document IDs to author IDs.\n",
    "# Same as in the atvb code.\n",
    "doc2author = {}\n",
    "for d, _ in enumerate(docs):\n",
    "    author_ids = []\n",
    "    for a, a_doc_ids in author2doc.items():\n",
    "        if d in a_doc_ids:\n",
    "            author_ids.append(a)\n",
    "    doc2author[d] = author_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process and vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize the documents.\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lemmatize the documents.\n",
    "\n",
    "# Lemmatize all words in documents.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olavur/Dropbox/my_folder/workstuff/DTU/thesis/code/gensim/gensim/models/phrases.py:248: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "# Compute bigrams.\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove rare and common tokens.\n",
    "\n",
    "# Filter out words that occur too frequently or too rarely.\n",
    "max_freq = 0.5\n",
    "min_wordcount = 20\n",
    "dictionary.filter_extremes(no_below=min_wordcount, no_above=max_freq)\n",
    "\n",
    "dict0 = dictionary[0]  # This sort of \"initializes\" dictionary.id2token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGcCAYAAADOLDodAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n54TGzMzMap4TGjMzM6t5/w+ZKiTWKpLyuAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb7946c9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Frequency distribution of words.\n",
    "\n",
    "one_doc = []\n",
    "for doc in docs:\n",
    "    one_doc.extend(doc)\n",
    "\n",
    "bow = dictionary.doc2bow(one_doc)\n",
    "word_freq = [cnt for _, cnt in bow]\n",
    "\n",
    "plt.plot(sorted(word_freq))\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('#Occurences')\n",
    "plt.title('Frequency distribution of words.\\nPower-law behaviour.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize data.\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 536\n",
      "Number of unique tokens: 2245\n",
      "Number of documents: 286\n"
     ]
    }
   ],
   "source": [
    "print('Number of authors: %d' % len(author2doc))\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(atmodel)\n",
    "AuthorTopicModel = atmodel.AuthorTopicModel\n",
    "reload(atmodelold)\n",
    "AuthorTopicModelOld = atmodelold.AuthorTopicModelOld\n",
    "reload(ldamodel)\n",
    "LdaModel = ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.77 s, sys: 0 ns, total: 5.77 s\n",
      "Wall time: 5.77 s\n"
     ]
    }
   ],
   "source": [
    "%time model = AuthorTopicModel(corpus=corpus, num_topics=10, id2word=dictionary.id2token, \\\n",
    "                author2doc=author2doc, doc2author=doc2author, id2author=id2author, var_lambda=None,  \\\n",
    "                 chunksize=2000, passes=10, update_every=1, \\\n",
    "                 alpha='symmetric', eta='symmetric', decay=0.5, offset=1.0,  \\\n",
    "                 eval_every=1, iterations=10, gamma_threshold=1e-10,  \\\n",
    "                 minimum_probability=0.01, random_state=1, ns_conf={},  \\\n",
    "                 minimum_phi_value=0.01, per_word_topics=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'from_iterable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-0bc88180c87d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'from_iterable'"
     ]
    }
   ],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_chain = chain.from_iterable([range(10), range(10, 20)])\n",
    "next(islice(generator_chain, 14, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import islice, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(islice(count(), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"classifier\" + 0.012*\"node\" + 0.008*\"vector\" + 0.007*\"recognition\" + 0.006*\"decision\" + 0.006*\"classification\" + 0.005*\"sequence\" + 0.005*\"class\" + 0.005*\"sample\" + 0.005*\"probability\"'),\n",
       " (1,\n",
       "  '0.010*\"cell\" + 0.009*\"activation\" + 0.008*\"hidden\" + 0.007*\"node\" + 0.005*\"propagation\" + 0.005*\"response\" + 0.005*\"hidden_unit\" + 0.005*\"energy\" + 0.004*\"back_propagation\" + 0.004*\"matrix\"'),\n",
       " (2,\n",
       "  '0.009*\"vector\" + 0.008*\"image\" + 0.007*\"hidden\" + 0.005*\"fig\" + 0.005*\"dynamic\" + 0.005*\"noise\" + 0.005*\"object\" + 0.004*\"energy\" + 0.004*\"memory\" + 0.004*\"matrix\"'),\n",
       " (3,\n",
       "  '0.013*\"vector\" + 0.011*\"hidden\" + 0.010*\"memory\" + 0.009*\"field\" + 0.005*\"hidden_unit\" + 0.004*\"threshold\" + 0.004*\"internal\" + 0.004*\"associative\" + 0.004*\"bit\" + 0.003*\"fig\"'),\n",
       " (4,\n",
       "  '0.020*\"cell\" + 0.009*\"firing\" + 0.008*\"stimulus\" + 0.007*\"synaptic\" + 0.007*\"activity\" + 0.006*\"image\" + 0.006*\"response\" + 0.006*\"spike\" + 0.005*\"potential\" + 0.004*\"current\"'),\n",
       " (5,\n",
       "  '0.007*\"hidden\" + 0.006*\"node\" + 0.005*\"image\" + 0.005*\"matrix\" + 0.004*\"class\" + 0.004*\"fig\" + 0.004*\"noise\" + 0.004*\"propagation\" + 0.003*\"recognition\" + 0.003*\"vector\"'),\n",
       " (6,\n",
       "  '0.009*\"speech\" + 0.009*\"region\" + 0.008*\"recognition\" + 0.006*\"chain\" + 0.006*\"probability\" + 0.005*\"class\" + 0.005*\"cell\" + 0.005*\"hidden\" + 0.004*\"domain\" + 0.004*\"distribution\"'),\n",
       " (7,\n",
       "  '0.011*\"cell\" + 0.007*\"memory\" + 0.006*\"response\" + 0.006*\"fig\" + 0.006*\"circuit\" + 0.006*\"current\" + 0.005*\"hopfield\" + 0.005*\"analog\" + 0.005*\"synapse\" + 0.005*\"activity\"'),\n",
       " (8,\n",
       "  '0.013*\"circuit\" + 0.006*\"memory\" + 0.005*\"control\" + 0.005*\"cell\" + 0.005*\"threshold\" + 0.005*\"fig\" + 0.004*\"voltage\" + 0.004*\"transistor\" + 0.004*\"current\" + 0.004*\"response\"'),\n",
       " (9,\n",
       "  '0.008*\"memory\" + 0.008*\"field\" + 0.008*\"cell\" + 0.007*\"map\" + 0.007*\"delay\" + 0.006*\"cortex\" + 0.006*\"image\" + 0.006*\"chip\" + 0.005*\"current\" + 0.005*\"synaptic\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics(num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yaser S.Abu-Mostafa\n",
      "Docs: [62]\n",
      "[(0, 0.17428370582074723),\n",
      " (1, 0.10229569024379424),\n",
      " (2, 0.062556106292013122),\n",
      " (3, 0.078817840485611065),\n",
      " (4, 0.068487942942868585),\n",
      " (5, 0.14869390057914703),\n",
      " (6, 0.17212355568609788),\n",
      " (7, 0.074170089610964149),\n",
      " (8, 0.047702469618850774),\n",
      " (9, 0.070868698719905782)]\n",
      "\n",
      "Geoffrey E. Hinton\n",
      "Docs: [143, 284, 230, 197]\n",
      "[(0, 0.1963942573033424),\n",
      " (1, 0.12792966363823302),\n",
      " (2, 0.23505329159063704),\n",
      " (3, 0.060305386421733033),\n",
      " (4, 0.04267590384413758),\n",
      " (5, 0.060980284135135593),\n",
      " (6, 0.2451247159367281),\n",
      " (8, 0.01574985863695311),\n",
      " (9, 0.01023414671028579)]\n",
      "\n",
      "Michael I. Jordan\n",
      "Docs: [237]\n",
      "[(0, 0.085651762012953936),\n",
      " (1, 0.065665448104732405),\n",
      " (2, 0.07777125401127058),\n",
      " (3, 0.050480420361483674),\n",
      " (4, 0.065721037891177864),\n",
      " (5, 0.086499723758504746),\n",
      " (6, 0.38914428858057321),\n",
      " (7, 0.039550645237331414),\n",
      " (8, 0.10733538353868659),\n",
      " (9, 0.032180036503285388)]\n",
      "\n",
      "James M. Bower\n",
      "Docs: [131, 101, 126, 127, 281, 208, 225]\n",
      "[(1, 0.013903403611000136),\n",
      " (4, 0.098066607370058775),\n",
      " (7, 0.11242612291693072),\n",
      " (8, 0.016186021191484681),\n",
      " (9, 0.74612850820488463)]\n"
     ]
    }
   ],
   "source": [
    "name = 'Yaser S.Abu-Mostafa'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(model.get_author_topics(author2id[name]))\n",
    "\n",
    "name = 'Geoffrey E. Hinton'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(model.get_author_topics(author2id[name]))\n",
    "\n",
    "name = 'Michael I. Jordan'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(model.get_author_topics(author2id[name]))\n",
    "\n",
    "name = 'James M. Bower'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(model.get_author_topics(author2id[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.32 s, sys: 4 ms, total: 7.32 s\n",
      "Wall time: 7.33 s\n"
     ]
    }
   ],
   "source": [
    "%time model2 = AuthorTopicModel(corpus=corpus, num_topics=10, id2word=dictionary.id2token, id2author=id2author, \\\n",
    "                   author2doc=author2doc, doc2author=doc2author, threshold=1e-10, \\\n",
    "                   iterations=10, passes=10, alpha=None, eta=None, decay=0.5, offset=1.0, \\\n",
    "                   eval_every=1, random_state=1, var_lambda=None, chunksize=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"vector\" + 0.012*\"memory\" + 0.007*\"associative\" + 0.005*\"control\" + 0.005*\"constraint\" + 0.005*\"recognition\" + 0.005*\"chip\" + 0.005*\"image\" + 0.004*\"hidden\" + 0.004*\"machine\"'),\n",
       " (1,\n",
       "  '0.014*\"memory\" + 0.007*\"probability\" + 0.007*\"vector\" + 0.005*\"chip\" + 0.005*\"pulse\" + 0.005*\"fig\" + 0.004*\"node\" + 0.004*\"cell\" + 0.004*\"capacity\" + 0.004*\"matrix\"'),\n",
       " (2,\n",
       "  '0.017*\"classifier\" + 0.015*\"circuit\" + 0.006*\"noise\" + 0.006*\"current\" + 0.006*\"fig\" + 0.006*\"node\" + 0.005*\"gaussian\" + 0.005*\"speech\" + 0.005*\"propagation\" + 0.005*\"decision\"'),\n",
       " (3,\n",
       "  '0.008*\"cell\" + 0.008*\"fig\" + 0.006*\"vector\" + 0.006*\"hidden\" + 0.006*\"velocity\" + 0.005*\"operator\" + 0.005*\"image\" + 0.004*\"activation\" + 0.004*\"receptor\" + 0.004*\"delay\"'),\n",
       " (4,\n",
       "  '0.009*\"image\" + 0.009*\"match\" + 0.008*\"processor\" + 0.007*\"classifier\" + 0.007*\"node\" + 0.007*\"element\" + 0.006*\"activation\" + 0.006*\"link\" + 0.005*\"nat\" + 0.005*\"fig\"'),\n",
       " (5,\n",
       "  '0.011*\"field\" + 0.010*\"cell\" + 0.007*\"synaptic\" + 0.005*\"cortical\" + 0.005*\"visual\" + 0.005*\"activity\" + 0.005*\"eye\" + 0.005*\"synapsis\" + 0.004*\"map\" + 0.004*\"phase\"'),\n",
       " (6,\n",
       "  '0.006*\"hidden\" + 0.006*\"recognition\" + 0.005*\"map\" + 0.005*\"vector\" + 0.005*\"node\" + 0.004*\"object\" + 0.004*\"speech\" + 0.004*\"matrix\" + 0.003*\"class\" + 0.003*\"sequence\"'),\n",
       " (7,\n",
       "  '0.013*\"role\" + 0.009*\"motion\" + 0.008*\"source\" + 0.007*\"regular\" + 0.007*\"visual\" + 0.006*\"markov\" + 0.006*\"threshold\" + 0.006*\"node\" + 0.005*\"code\" + 0.005*\"depth\"'),\n",
       " (8,\n",
       "  '0.028*\"cell\" + 0.013*\"response\" + 0.013*\"stimulus\" + 0.010*\"spike\" + 0.009*\"firing\" + 0.009*\"current\" + 0.009*\"image\" + 0.009*\"potential\" + 0.006*\"activity\" + 0.006*\"membrane\"'),\n",
       " (9,\n",
       "  '0.014*\"hidden\" + 0.009*\"hidden_unit\" + 0.008*\"distribution\" + 0.008*\"node\" + 0.007*\"image\" + 0.006*\"activation\" + 0.006*\"propagation\" + 0.006*\"back_propagation\" + 0.005*\"speech\" + 0.005*\"sample\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.show_topics(num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yaser S.Abu-Mostafa\n",
      "Docs: [62]\n",
      "[(0, 0.12257888012385142),\n",
      " (1, 0.18839815551960026),\n",
      " (2, 0.036637297625550132),\n",
      " (3, 0.015498644507138377),\n",
      " (4, 0.072386020997623229),\n",
      " (5, 0.075906889662321148),\n",
      " (6, 0.34904030995007596),\n",
      " (7, 0.022928611918427422),\n",
      " (8, 0.068558327925279966),\n",
      " (9, 0.048066861770131898)]\n",
      "\n",
      "Geoffrey E. Hinton\n",
      "Docs: [143, 284, 230, 197]\n",
      "[(0, 0.017941678995404806),\n",
      " (1, 0.037633561393485344),\n",
      " (2, 0.040229587442296211),\n",
      " (6, 0.86860470412607893)]\n",
      "\n",
      "Michael I. Jordan\n",
      "Docs: [237]\n",
      "[(0, 0.23458706049871778),\n",
      " (1, 0.028074129427662773),\n",
      " (2, 0.092872627256054469),\n",
      " (3, 0.060285180922721039),\n",
      " (4, 0.05771159235103844),\n",
      " (5, 0.27973835933458052),\n",
      " (6, 0.13822500759562903),\n",
      " (7, 0.015239077050084931),\n",
      " (8, 0.052855346935884104),\n",
      " (9, 0.040411618627626808)]\n",
      "\n",
      "James M. Bower\n",
      "Docs: [131, 101, 126, 127, 281, 208, 225]\n",
      "[(5, 0.11028614207196175), (6, 0.41931814978983267), (8, 0.4701441896634681)]\n"
     ]
    }
   ],
   "source": [
    "name = 'Yaser S.Abu-Mostafa'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(model2.get_author_topics(author2id[name]))\n",
    "\n",
    "name = 'Geoffrey E. Hinton'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(model2.get_author_topics(author2id[name]))\n",
    "\n",
    "name = 'Michael I. Jordan'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(model2.get_author_topics(author2id[name]))\n",
    "\n",
    "name = 'James M. Bower'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(model2.get_author_topics(author2id[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization speed-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 166\n",
      "Number of unique tokens: 681\n",
      "Number of documents: 90\n",
      "Speed-up 6.6498740554156175\n"
     ]
    }
   ],
   "source": [
    "print('Number of authors: %d' % len(author2doc))\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))\n",
    "print('Speed-up', 2.64 / 0.397)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 536\n",
      "Number of unique tokens: 2245\n",
      "Number of documents: 286\n",
      "Speed-up 5.084175084175084\n"
     ]
    }
   ],
   "source": [
    "print('Number of authors: %d' % len(author2doc))\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))\n",
    "print('Speed-up', 15.1 / 2.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 2720\n",
      "Number of unique tokens: 8640\n",
      "Number of documents: 1740\n",
      "Speed-up 2.4383561643835616\n"
     ]
    }
   ],
   "source": [
    "print('Number of authors: %d' % len(author2doc))\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))\n",
    "print('Speed-up', (2 * 60 + 58) / (1 * 60 + 13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_docs = 10\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "small_doc2author = deepcopy(dict(list(doc2author.items())[:n_docs]))\n",
    "small_doc2author = dict(small_doc2author)\n",
    "\n",
    "small_corpus = corpus[:n_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authors_ids = set()\n",
    "for d, a_doc_ids in small_doc2author.items():\n",
    "    for a in a_doc_ids:\n",
    "        authors_ids.add(a)\n",
    "\n",
    "authors_ids = list(authors_ids)\n",
    "author_id_dict = dict(zip(authors_ids, range(len(authors_ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d, a_ids in small_doc2author.items():\n",
    "    for i, a in enumerate(a_ids):\n",
    "        small_doc2author[d][i] = author_id_dict[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a mapping from author IDs to document IDs.\n",
    "small_author2doc = {}\n",
    "for a in range(len(author_id_dict)):\n",
    "    small_author2doc[a] = []\n",
    "    for d, a_ids in small_doc2author.items():\n",
    "        if a in a_ids:\n",
    "            small_author2doc[a].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "author_id_dict_rev = dict(zip(range(len(authors_ids)), authors_ids))\n",
    "\n",
    "small_id2author = {}\n",
    "for a, a_id in author_id_dict_rev.items():\n",
    "    small_id2author[a] = id2author[a_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi is 10 x 681 x 10 (68100 elements)\n",
      "mu is 10 x 681 x 21 (143010 elements)\n"
     ]
    }
   ],
   "source": [
    "print('phi is %d x %d x %d (%d elements)' %(len(small_corpus), len(dictionary.id2token), 10,\n",
    "                                            len(small_corpus) * len(dictionary.id2token) * 10))\n",
    "print('mu is %d x %d x %d (%d elements)' %(len(small_corpus), len(dictionary.id2token), len(small_author2doc),\n",
    "                                            len(small_corpus) * len(dictionary.id2token) * len(small_author2doc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(ldamodel)\n",
    "LdaModel = ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 7.6 s, total: 29.3 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%time lda = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary.id2token, passes=10, gamma_threshold=1e-10, \\\n",
    "               iterations=10, alpha='symmetric', eta='symmetric', eval_every=0, chunksize=2000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 304 ms, sys: 0 ns, total: 304 ms\n",
      "Wall time: 303 ms\n",
      "Bound: -2.424e+05\n"
     ]
    }
   ],
   "source": [
    "%time lda_bound = lda.bound(sample(corpus, 10))\n",
    "print('Bound: %.3e' % lda_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 308 ms, sys: 0 ns, total: 308 ms\n",
      "Wall time: 303 ms\n",
      "Bound: -3.365e+05\n"
     ]
    }
   ],
   "source": [
    "%time lda_bound = lda.bound(sample(corpus, 10))\n",
    "print('Bound: %.3e' % lda_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"cell\" + 0.011*\"neuron\" + 0.008*\"visual\" + 0.008*\"response\" + 0.007*\"stimulus\" + 0.006*\"activity\" + 0.006*\"field\" + 0.004*\"motion\" + 0.004*\"cortex\" + 0.004*\"layer\"'),\n",
       " (1,\n",
       "  '0.006*\"bound\" + 0.005*\"class\" + 0.005*\"node\" + 0.004*\"generalization\" + 0.004*\"sample\" + 0.004*\"let\" + 0.004*\"estimate\" + 0.004*\"tree\" + 0.004*\"approximation\" + 0.004*\"theorem\"'),\n",
       " (2,\n",
       "  '0.009*\"class\" + 0.007*\"recognition\" + 0.007*\"classifier\" + 0.005*\"classification\" + 0.005*\"word\" + 0.005*\"distance\" + 0.005*\"image\" + 0.005*\"hidden\" + 0.004*\"character\" + 0.004*\"trained\"'),\n",
       " (3,\n",
       "  '0.021*\"image\" + 0.006*\"gaussian\" + 0.005*\"face\" + 0.005*\"component\" + 0.004*\"matrix\" + 0.003*\"prior\" + 0.003*\"density\" + 0.003*\"noise\" + 0.003*\"hidden\" + 0.003*\"object\"'),\n",
       " (4,\n",
       "  '0.009*\"control\" + 0.006*\"action\" + 0.006*\"policy\" + 0.005*\"optimal\" + 0.005*\"dynamic\" + 0.005*\"reinforcement\" + 0.005*\"signal\" + 0.004*\"controller\" + 0.004*\"noise\" + 0.003*\"trajectory\"'),\n",
       " (5,\n",
       "  '0.009*\"memory\" + 0.004*\"rule\" + 0.004*\"net\" + 0.004*\"bit\" + 0.004*\"layer\" + 0.004*\"architecture\" + 0.004*\"recognition\" + 0.003*\"matrix\" + 0.003*\"processor\" + 0.003*\"machine\"'),\n",
       " (6,\n",
       "  '0.007*\"hidden\" + 0.007*\"layer\" + 0.007*\"speech\" + 0.006*\"node\" + 0.006*\"net\" + 0.005*\"word\" + 0.004*\"sequence\" + 0.004*\"activation\" + 0.004*\"context\" + 0.004*\"language\"'),\n",
       " (7,\n",
       "  '0.010*\"neuron\" + 0.008*\"circuit\" + 0.008*\"signal\" + 0.006*\"voltage\" + 0.006*\"channel\" + 0.006*\"chip\" + 0.005*\"analog\" + 0.004*\"frequency\" + 0.004*\"cell\" + 0.004*\"spike\"'),\n",
       " (8,\n",
       "  '0.008*\"object\" + 0.005*\"mixture\" + 0.004*\"hidden\" + 0.004*\"likelihood\" + 0.004*\"recognition\" + 0.004*\"em\" + 0.003*\"gaussian\" + 0.003*\"matrix\" + 0.003*\"view\" + 0.003*\"component\"'),\n",
       " (9,\n",
       "  '0.011*\"neuron\" + 0.006*\"dynamic\" + 0.005*\"matrix\" + 0.004*\"noise\" + 0.004*\"solution\" + 0.003*\"field\" + 0.003*\"condition\" + 0.003*\"gradient\" + 0.003*\"convergence\" + 0.003*\"limit\"')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "from bokeh.models.layouts import Row, Column\n",
    "from bokeh.models import Title, Legend\n",
    "from bokeh.plotting import figure, output_file, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"e8c53ef7-1db1-4f6d-8aac-8c90f6d131d0\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = \"1\";\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      Bokeh.$(\"#e8c53ef7-1db1-4f6d-8aac-8c90f6d131d0\").text(\"BokehJS successfully loaded.\");\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"e8c53ef7-1db1-4f6d-8aac-8c90f6d131d0\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'e8c53ef7-1db1-4f6d-8aac-8c90f6d131d0' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.3.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.3.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      Bokeh.$(\"#e8c53ef7-1db1-4f6d-8aac-8c90f6d131d0\").text(\"BokehJS is loading...\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.3.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.3.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.3.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === \"1\")) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === \"1\") {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (!force) {\n",
       "      var cell = $(\"#e8c53ef7-1db1-4f6d-8aac-8c90f6d131d0\").parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <div class=\"plotdiv\" id=\"2aabfb64-a772-4315-8ffd-802566cfc9ef\"></div>\n",
       "    </div>\n",
       "<script type=\"text/javascript\">\n",
       "  \n",
       "  (function(global) {\n",
       "    function now() {\n",
       "      return new Date();\n",
       "    }\n",
       "  \n",
       "    var force = \"\";\n",
       "  \n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "      window._bokeh_onload_callbacks = [];\n",
       "      window._bokeh_is_loading = undefined;\n",
       "    }\n",
       "  \n",
       "  \n",
       "    \n",
       "    if (typeof (window._bokeh_timeout) === \"undefined\" || force !== \"\") {\n",
       "      window._bokeh_timeout = Date.now() + 0;\n",
       "      window._bokeh_failed_load = false;\n",
       "    }\n",
       "  \n",
       "    var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "       \"<div style='background-color: #fdd'>\\n\"+\n",
       "       \"<p>\\n\"+\n",
       "       \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "       \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "       \"</p>\\n\"+\n",
       "       \"<ul>\\n\"+\n",
       "       \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "       \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "       \"</ul>\\n\"+\n",
       "       \"<code>\\n\"+\n",
       "       \"from bokeh.resources import INLINE\\n\"+\n",
       "       \"output_notebook(resources=INLINE)\\n\"+\n",
       "       \"</code>\\n\"+\n",
       "       \"</div>\"}};\n",
       "  \n",
       "    function display_loaded() {\n",
       "      if (window.Bokeh !== undefined) {\n",
       "        Bokeh.$(\"#2aabfb64-a772-4315-8ffd-802566cfc9ef\").text(\"BokehJS successfully loaded.\");\n",
       "      } else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(display_loaded, 100)\n",
       "      }\n",
       "    }\n",
       "  \n",
       "    function run_callbacks() {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "      delete window._bokeh_onload_callbacks\n",
       "      console.info(\"Bokeh: all callbacks have finished\");\n",
       "    }\n",
       "  \n",
       "    function load_libs(js_urls, callback) {\n",
       "      window._bokeh_onload_callbacks.push(callback);\n",
       "      if (window._bokeh_is_loading > 0) {\n",
       "        console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "        return null;\n",
       "      }\n",
       "      if (js_urls == null || js_urls.length === 0) {\n",
       "        run_callbacks();\n",
       "        return null;\n",
       "      }\n",
       "      console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      window._bokeh_is_loading = js_urls.length;\n",
       "      for (var i = 0; i < js_urls.length; i++) {\n",
       "        var url = js_urls[i];\n",
       "        var s = document.createElement('script');\n",
       "        s.src = url;\n",
       "        s.async = false;\n",
       "        s.onreadystatechange = s.onload = function() {\n",
       "          window._bokeh_is_loading--;\n",
       "          if (window._bokeh_is_loading === 0) {\n",
       "            console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "            run_callbacks()\n",
       "          }\n",
       "        };\n",
       "        s.onerror = function() {\n",
       "          console.warn(\"failed to load library \" + url);\n",
       "        };\n",
       "        console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      }\n",
       "    };var element = document.getElementById(\"2aabfb64-a772-4315-8ffd-802566cfc9ef\");\n",
       "    if (element == null) {\n",
       "      console.log(\"Bokeh: ERROR: autoload.js configured with elementid '2aabfb64-a772-4315-8ffd-802566cfc9ef' but no matching script tag was found. \")\n",
       "      return false;\n",
       "    }\n",
       "  \n",
       "    var js_urls = [];\n",
       "  \n",
       "    var inline_js = [\n",
       "      function(Bokeh) {\n",
       "        Bokeh.$(function() {\n",
       "            var docs_json = {\"0595e977-9144-4c9c-8ec2-036a409f9d7f\":{\"roots\":{\"references\":[{\"attributes\":{\"active_drag\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"77ea5427-38b0-447d-b472-838a7047850d\",\"type\":\"PanTool\"},{\"id\":\"8bf8beae-cfbe-497c-97c1-2d17e5caf97e\",\"type\":\"WheelZoomTool\"},{\"id\":\"2669932b-1d4d-4491-bb80-6db0e6c03d3a\",\"type\":\"BoxZoomTool\"},{\"id\":\"fac74756-4def-49f8-9892-9b17b902d3dc\",\"type\":\"SaveTool\"},{\"id\":\"b4e0aa58-8c44-4176-8bed-b24fe471f0fb\",\"type\":\"ResetTool\"},{\"id\":\"9450f1cb-0edf-4825-a410-01ccea0a9825\",\"type\":\"HelpTool\"}]},\"id\":\"441213e9-b8f0-442e-8b84-aad48c3f43ca\",\"type\":\"Toolbar\"},{\"attributes\":{\"plot\":{\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"8bf8beae-cfbe-497c-97c1-2d17e5caf97e\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"y\",\"x\"],\"data\":{\"x\":[0.1,0.1090909090909091,0.1181818181818182,0.1272727272727273,0.13636363636363635,0.14545454545454545,0.15454545454545454,0.16363636363636364,0.17272727272727273,0.18181818181818182,0.19090909090909092,0.2,0.2090909090909091,0.2181818181818182,0.22727272727272727,0.23636363636363636,0.24545454545454545,0.2545454545454545,0.26363636363636367,0.2727272727272727,0.28181818181818186,0.2909090909090909,0.3,0.3090909090909091,0.3181818181818182,0.32727272727272727,0.33636363636363636,0.34545454545454546,0.3545454545454545,0.36363636363636365,0.3727272727272727,0.38181818181818183,0.3909090909090909,0.4,0.40909090909090906,0.4181818181818182,0.42727272727272725,0.4363636363636364,0.44545454545454544,0.4545454545454546,0.4636363636363636,0.47272727272727266,0.4818181818181818,0.49090909090909085,0.5,0.509090909090909,0.5181818181818182,0.5272727272727272,0.5363636363636364,0.5454545454545454,0.5545454545454546,0.5636363636363636,0.5727272727272728,0.5818181818181818,0.5909090909090909,0.6,0.609090909090909,0.6181818181818182,0.6272727272727272,0.6363636363636364,0.6454545454545454,0.6545454545454545,0.6636363636363636,0.6727272727272727,0.6818181818181818,0.6909090909090908,0.7,0.709090909090909,0.7181818181818181,0.7272727272727272,0.7363636363636363,0.7454545454545454,0.7545454545454545,0.7636363636363636,0.7727272727272727,0.7818181818181817,0.7909090909090909,0.7999999999999999,0.8090909090909091,0.8181818181818181,0.8272727272727273,0.8363636363636363,0.8454545454545453,0.8545454545454545,0.8636363636363635,0.8727272727272727,0.8818181818181817,0.8909090909090909,0.8999999999999999,0.9090909090909091,0.9181818181818181,0.9272727272727272,0.9363636363636363,0.9454545454545454,0.9545454545454545,0.9636363636363636,0.9727272727272727,0.9818181818181817,0.9909090909090909,1.0,10000.0],\"y\":[-19.63953051528936,-18.793243548710016,-18.07531222032236,-17.458260766736373,-16.92193953031814,-16.45123557808641,-16.034591336301133,-15.663017012478901,-15.329414883204695,-15.028106294758363,-14.754493805659994,-14.504815471470472,-14.275963228586408,-14.065346681520023,-13.870789580716085,-13.690450189632518,-13.52275934759476,-13.366371804501128,-13.220127623847832,-13.083021304816267,-12.954176880424246,-12.832827684491546,-12.718299797078418,-12.609998411076432,-12.507396535732322,-12.410025582711356,-12.317467478553517,-12.229348022353522,-12.145331265170928,-12.065114732374965,-11.988425345015193,-11.91501592372001,-11.844662180298723,-11.7771601194634,-11.71232378687914,-11.649983310845212,-11.589983193879233,-11.532180817764155,-11.47644513156717,-11.422655497017928,-11.37070066965106,-11.320477897439993,-11.271892121407266,-11.22485526499477,-11.179285600899707,-11.135107185695363,-11.092249353914415,-11.05064626442031,-11.010236492864935,-10.970962664857646,-10.932771125175538,-10.895611638947365,-10.859437121259933,-10.824203392079708,-10.78986895376463,-10.756394788771475,-10.723744175449923,-10.691882520062565,-10.660777203385772,-10.630397440434281,-10.60071415201657,-10.571699846971624,-10.543328514063699,-10.515575522622239,-10.488417531111455,-10.461832402899917,-10.43579912857622,-10.410297754223905,-10.385309315128179,-10.360815774439661,-10.336799966367362,-10.313245543514673,-10.29013692800949,-10.267459266112681,-10.245198386018917,-10.223340758590373,-10.201873460787763,-10.180784141584423,-10.160060990168589,-10.139692706256131,-10.119668472351783,-10.099977927810851,-10.080611144566204,-10.061558604396776,-10.042811177624248,-10.024360103134045,-10.006196969625243,-9.988313698001917,-9.970702524825336,-9.953355986753014,-9.93626690589638,-9.919428376034208,-9.902833749623822,-9.886476625556556,-9.870350837607992,-9.854450443537246,-9.83876971479301,-9.823303126787117,-9.808045349699354,-9.792991239779818,-0.005485203735434041]}},\"id\":\"559d20e9-fb31-4a29-988d-54daa08896c3\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"plot\":{\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"77ea5427-38b0-447d-b472-838a7047850d\",\"type\":\"PanTool\"},{\"attributes\":{\"callback\":null},\"id\":\"d4c4915c-0724-42a1-9590-3dd1e4713e3f\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null},\"id\":\"8bb728e6-9a63-4048-aadb-cb1a5fc8041e\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1b9bbc76-5e10-407c-8485-00b2a1f6a602\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"d36325f3-8500-4a59-812a-17a72a63b34b\",\"type\":\"Circle\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"2859e1a3-85bf-49be-b069-803ea6b761cf\",\"type\":\"BasicTicker\"}},\"id\":\"0d077d98-93ed-436e-9af0-62673433f534\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"0a6593c9-6edb-4abf-bc35-8429912ea2bc\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"fac74756-4def-49f8-9892-9b17b902d3dc\",\"type\":\"SaveTool\"},{\"attributes\":{\"formatter\":{\"id\":\"f31ff590-0027-48be-a717-83aaa1d1acd7\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"2859e1a3-85bf-49be-b069-803ea6b761cf\",\"type\":\"BasicTicker\"}},\"id\":\"691cdacc-605e-414c-9705-c1fc8d669bea\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"2859e1a3-85bf-49be-b069-803ea6b761cf\",\"type\":\"BasicTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"0f3ae6bf-0fbd-4f70-8dc7-6885077edaa2\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"formatter\":{\"id\":\"1b9bbc76-5e10-407c-8485-00b2a1f6a602\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"0a6593c9-6edb-4abf-bc35-8429912ea2bc\",\"type\":\"BasicTicker\"}},\"id\":\"bd91b36e-7a2c-45c1-bcc6-0a685fbfe1b5\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"559d20e9-fb31-4a29-988d-54daa08896c3\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"d36325f3-8500-4a59-812a-17a72a63b34b\",\"type\":\"Circle\"},\"hover_glyph\":null,\"nonselection_glyph\":{\"id\":\"8e3c408b-80c5-4eeb-b2dc-0be8caecb8df\",\"type\":\"Circle\"},\"selection_glyph\":null},\"id\":\"d587b117-fda3-496e-9d70-c864b317c435\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"plot\":{\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"0a6593c9-6edb-4abf-bc35-8429912ea2bc\",\"type\":\"BasicTicker\"}},\"id\":\"d5ebfa70-34c9-4d3f-a522-f3906ab5b1e5\",\"type\":\"Grid\"},{\"attributes\":{\"plot\":{\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"9450f1cb-0edf-4825-a410-01ccea0a9825\",\"type\":\"HelpTool\"},{\"attributes\":{\"below\":[{\"id\":\"bd91b36e-7a2c-45c1-bcc6-0a685fbfe1b5\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"691cdacc-605e-414c-9705-c1fc8d669bea\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"bd91b36e-7a2c-45c1-bcc6-0a685fbfe1b5\",\"type\":\"LinearAxis\"},{\"id\":\"d5ebfa70-34c9-4d3f-a522-f3906ab5b1e5\",\"type\":\"Grid\"},{\"id\":\"691cdacc-605e-414c-9705-c1fc8d669bea\",\"type\":\"LinearAxis\"},{\"id\":\"0d077d98-93ed-436e-9af0-62673433f534\",\"type\":\"Grid\"},{\"id\":\"0f3ae6bf-0fbd-4f70-8dc7-6885077edaa2\",\"type\":\"BoxAnnotation\"},{\"id\":\"d587b117-fda3-496e-9d70-c864b317c435\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"2340815d-bb12-4d9c-9f39-534ffe816602\",\"type\":\"Title\"},\"tool_events\":{\"id\":\"b325a5ac-51b5-416b-a7a6-d0b337f9e77d\",\"type\":\"ToolEvents\"},\"toolbar\":{\"id\":\"441213e9-b8f0-442e-8b84-aad48c3f43ca\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"d4c4915c-0724-42a1-9590-3dd1e4713e3f\",\"type\":\"DataRange1d\"},\"y_range\":{\"id\":\"8bb728e6-9a63-4048-aadb-cb1a5fc8041e\",\"type\":\"DataRange1d\"}},\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"b325a5ac-51b5-416b-a7a6-d0b337f9e77d\",\"type\":\"ToolEvents\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"8e3c408b-80c5-4eeb-b2dc-0be8caecb8df\",\"type\":\"Circle\"},{\"attributes\":{\"plot\":null,\"text\":null},\"id\":\"2340815d-bb12-4d9c-9f39-534ffe816602\",\"type\":\"Title\"},{\"attributes\":{\"plot\":{\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"b4e0aa58-8c44-4176-8bed-b24fe471f0fb\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"f31ff590-0027-48be-a717-83aaa1d1acd7\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"overlay\":{\"id\":\"0f3ae6bf-0fbd-4f70-8dc7-6885077edaa2\",\"type\":\"BoxAnnotation\"},\"plot\":{\"id\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"2669932b-1d4d-4491-bb80-6db0e6c03d3a\",\"type\":\"BoxZoomTool\"}],\"root_ids\":[\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.3\"}};\n",
       "            var render_items = [{\"docid\":\"0595e977-9144-4c9c-8ec2-036a409f9d7f\",\"elementid\":\"2aabfb64-a772-4315-8ffd-802566cfc9ef\",\"modelid\":\"d9c3a3f3-40eb-4626-aabd-70aa2932c3be\"}];\n",
       "            \n",
       "            Bokeh.embed.embed_items(docs_json, render_items);\n",
       "        });\n",
       "      },\n",
       "      function(Bokeh) {\n",
       "      }\n",
       "    ];\n",
       "  \n",
       "    function run_inline_js() {\n",
       "      \n",
       "      if ((window.Bokeh !== undefined) || (force === \"1\")) {\n",
       "        for (var i = 0; i < inline_js.length; i++) {\n",
       "          inline_js[i](window.Bokeh);\n",
       "        }if (force === \"1\") {\n",
       "          display_loaded();\n",
       "        }} else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(run_inline_js, 100);\n",
       "      } else if (!window._bokeh_failed_load) {\n",
       "        console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "        window._bokeh_failed_load = true;\n",
       "      } else if (!force) {\n",
       "        var cell = $(\"#2aabfb64-a772-4315-8ffd-802566cfc9ef\").parents('.cell').data().cell;\n",
       "        cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "      }\n",
       "  \n",
       "    }\n",
       "  \n",
       "    if (window._bokeh_is_loading === 0) {\n",
       "      console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "      run_inline_js();\n",
       "    } else {\n",
       "      load_libs(js_urls, function() {\n",
       "        console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }(this));\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure()\n",
    "x = np.zeros(101)\n",
    "x[:100] = np.linspace(0.1, 1, 100)\n",
    "x[100] = 10000\n",
    "p.circle(x, psi(x) - psi(x.sum()))\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Line profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(atmodel)\n",
    "AuthorTopicModel = atmodel.AuthorTopicModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 728.228 s\n",
      "File: /home/olavur/Dropbox/my_folder/workstuff/DTU/thesis/code/gensim/gensim/models/atmodel.py\n",
      "Function: inference at line 152\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   152                                               def inference(self, corpus=None, var_lambda=None):\n",
      "   153         1            4      4.0      0.0          if corpus is None:\n",
      "   154                                                       # TODO: is copy necessary here?\n",
      "   155                                                       corpus = self.corpus.copy()\n",
      "   156                                           \n",
      "   157         1            5      5.0      0.0          self.num_docs = len(corpus)  # TODO: this needs to be different if the algorithm is truly online.\n",
      "   158                                           \n",
      "   159         1          355    355.0      0.0          logger.info('Starting inference. Training on %d documents.', len(corpus))\n",
      "   160                                           \n",
      "   161         1            3      3.0      0.0          vectorized = False # FIXME: set to True.\n",
      "   162         1            3      3.0      0.0          numstable_sm = False # FIXME: set to True.\n",
      "   163                                           \n",
      "   164         1            2      2.0      0.0          if not numstable_sm:\n",
      "   165         1            4      4.0      0.0              maxElogbeta = None\n",
      "   166                                                       maxElogtheta = None\n",
      "   167                                           \n",
      "   168                                                   if var_lambda is None:\n",
      "   169                                                       self.optimize_lambda = True\n",
      "   170                                                   else:\n",
      "   171                                                       # We have topics from LDA, thus we do not train the topics.\n",
      "   172         1            4      4.0      0.0              self.optimize_lambda = False\n",
      "   173         1         3120   3120.0      0.0  \n",
      "   174         1           49     49.0      0.0          # Initial values of gamma and lambda.\n",
      "   175         1           14     14.0      0.0          # Parameters of gamma distribution same as in `ldamodel`.\n",
      "   176                                                   var_gamma = self.random_state.gamma(100., 1. / 100.,\n",
      "   177         1            4      4.0      0.0                  (self.num_authors, self.num_topics))\n",
      "   178         1            5      5.0      0.0          tilde_gamma = var_gamma.copy()\n",
      "   179         1        11563  11563.0      0.0          self.var_gamma = var_gamma\n",
      "   180         1          141    141.0      0.0  \n",
      "   181                                                   if var_lambda is None:\n",
      "   182                                                       var_lambda = self.random_state.gamma(100., 1. / 100.,\n",
      "   183                                                               (self.num_topics, self.num_terms))\n",
      "   184                                                       tilde_lambda = var_lambda.copy()\n",
      "   185                                                   else:\n",
      "   186         1           10     10.0      0.0              self.norm_lambda = var_lambda.copy()\n",
      "   187                                                       for k in xrange(self.num_topics):\n",
      "   188         1            8      8.0      0.0                  self.norm_lambda[k, :] = var_lambda[k, :] / var_lambda.sum(axis=1)[k]\n",
      "   189                                                   \n",
      "   190                                                   self.var_lambda = var_lambda\n",
      "   191         1       370334 370334.0      0.1  \n",
      "   192         1      1157125 1157125.0      0.2          var_phi = dict()  # TODO: remove once non-vectorized code is not used anymore.\n",
      "   193         1            4      4.0      0.0  \n",
      "   194                                                   # Initialize dirichlet expectations.\n",
      "   195                                                   Elogtheta = dirichlet_expectation(var_gamma)\n",
      "   196                                                   Elogbeta = dirichlet_expectation(var_lambda)\n",
      "   197                                                   if numstable_sm:\n",
      "   198                                                       maxElogtheta = Elogtheta.max()\n",
      "   199         1          551    551.0      0.0              maxElogbeta = Elogbeta.max(axis=0)\n",
      "   200         1         1720   1720.0      0.0              expElogtheta = numpy.exp(Elogtheta - maxElogtheta)\n",
      "   201                                                       expElogbeta = numpy.exp(Elogbeta - maxElogbeta)\n",
      "   202         1            3      3.0      0.0          else:\n",
      "   203                                                       expElogtheta = numpy.exp(Elogtheta)\n",
      "   204                                                       expElogbeta = numpy.exp(Elogbeta)\n",
      "   205                                           \n",
      "   206                                                   if self.eval_every > 0:\n",
      "   207                                                       word_bound = self.word_bound(corpus, Elogtheta, Elogbeta, maxElogtheta, maxElogbeta)\n",
      "   208         2           10      5.0      0.0              theta_bound = self.theta_bound(Elogtheta)\n",
      "   209         1            2      2.0      0.0              beta_bound = self.beta_bound(Elogbeta)\n",
      "   210      1741         6426      3.7      0.0              bound = word_bound + theta_bound + beta_bound\n",
      "   211                                                       logger.info('Total bound: %.3e. Word bound: %.3e. theta bound: %.3e. beta bound: %.3e.', bound, word_bound, theta_bound, beta_bound)\n",
      "   212                                                   for _pass in xrange(self.passes):\n",
      "   213      1740        21268     12.2      0.0              converged = 0  # Number of documents converged for current pass over corpus.\n",
      "   214      1740       359952    206.9      0.0              for d, doc in enumerate(corpus):\n",
      "   215      1740       213240    122.6      0.0                  # TODO: a smarter of computing rho may be necessary. In ldamodel,\n",
      "   216      1740         5804      3.3      0.0                  # it's: pow(offset + pass_ + (self.num_updates / chunksize), -decay).\n",
      "   217                                                           rhot = self.rho(d + _pass)\n",
      "   218      1740         3509      2.0      0.0                  ids = numpy.array([id for id, _ in doc])  # Word IDs in doc.\n",
      "   219                                                           cts = numpy.array([cnt for _, cnt in doc])  # Word counts.\n",
      "   220                                                           authors_d = self.doc2author[d]  # List of author IDs for document d.\n",
      "   221                                           \n",
      "   222                                                           if vectorized:\n",
      "   223                                                               phinorm = self.compute_phinorm(ids, authors_d, Elogtheta, Elogbeta, maxElogtheta, maxElogbeta)\n",
      "   224      1740      2172516   1248.6      0.3                  else:\n",
      "   225                                                               var_phi = dict()\n",
      "   226                                           \n",
      "   227      1740        47495     27.3      0.0                  # TODO: if not used, get rid of these.\n",
      "   228      1740       106401     61.1      0.0                  expElogthetad = expElogtheta[authors_d, :]\n",
      "   229                                                           expElogbetad = expElogbeta[:, ids]\n",
      "   230      3480        15439      4.4      0.0  \n",
      "   231                                                           for iteration in xrange(self.iterations):\n",
      "   232                                                               #logger.info('iteration %i', iteration)\n",
      "   233      1740        16311      9.4      0.0  \n",
      "   234                                                               lastgamma = tilde_gamma[authors_d, :]\n",
      "   235                                           \n",
      "   236      1740         4061      2.3      0.0                      ## Update phi.\n",
      "   237    953484      1988572      2.1      0.3                      if not vectorized:\n",
      "   238    951744      1886620      2.0      0.3                          for v in ids:\n",
      "   239   3141324      6424372      2.0      0.9                              phi_sum = 0.0\n",
      "   240  24085380     49026745      2.0      6.7                              for a in authors_d:\n",
      "   241  21895800     59556256      2.7      8.2                                  for k in xrange(self.num_topics):\n",
      "   242  21895800     53252861      2.4      7.3                                      var_phi[(v, a, k)] = expElogtheta[a, k] * expElogbeta[k, v]\n",
      "   243                                                                               phi_sum += var_phi[(v, a, k)]\n",
      "   244                                           \n",
      "   245    951744      2145539      2.3      0.3                              # Normalize phi over k.\n",
      "   246   3141324      6397555      2.0      0.9                              phi_norm_const = 1.0 / (phi_sum + 1e-100)\n",
      "   247  24085380     48475653      2.0      6.7                              for a in authors_d:\n",
      "   248  21895800     52318586      2.4      7.2                                  for k in xrange(self.num_topics):\n",
      "   249                                                                               var_phi[(v, a, k)] *= phi_norm_const\n",
      "   250      5731        13183      2.3      0.0  \n",
      "   251     43901        99066      2.3      0.0                          for a in authors_d:\n",
      "   252     39910        97817      2.5      0.0                              for k in xrange(self.num_topics):\n",
      "   253  21935710     46111162      2.1      6.3                                  tilde_gamma[a, k] = 0.0\n",
      "   254  21895800     96645068      4.4     13.3                                  for vi, v in enumerate(ids):\n",
      "   255     39910       176150      4.4      0.0                                      tilde_gamma[a, k] += cts[vi] * var_phi[(v, a, k)]\n",
      "   256     39910       111018      2.8      0.0                                  tilde_gamma[a, k] *= len(self.author2doc[a])\n",
      "   257                                                                           tilde_gamma[a, k] += self.alpha[k]\n",
      "   258                                                               else:\n",
      "   259                                                                   # Update gamma.\n",
      "   260                                                                   for a in authors_d:\n",
      "   261                                                                       tilde_gamma[a, :] = self.alpha + len(self.author2doc[a]) * expElogtheta[a, :] * numpy.dot(cts / phinorm, expElogbetad.T)\n",
      "   262                                           \n",
      "   263                                                               # Update gamma and lambda.\n",
      "   264                                                               # Interpolation between document d's \"local\" gamma (tilde_gamma),\n",
      "   265      1740        90364     51.9      0.0                      # and \"global\" gamma (var_gamma). Same goes for lambda.\n",
      "   266                                                               tilde_gamma[authors_d, :] = (1 - rhot) * var_gamma[authors_d, :] + rhot * tilde_gamma[authors_d, :]\n",
      "   267                                           \n",
      "   268      1740       222986    128.2      0.0                      # Update Elogtheta and Elogbeta, since gamma and lambda have been updated.\n",
      "   269      1740         4349      2.5      0.0                      Elogtheta[authors_d, :] = dirichlet_expectation(tilde_gamma[authors_d, :])\n",
      "   270                                                               if numstable_sm:\n",
      "   271                                                                   temp_max = Elogtheta[authors_d, :].max()\n",
      "   272                                                                   maxElogtheta = temp_max if temp_max > maxElogtheta else maxElogtheta\n",
      "   273                                                                   expElogtheta[authors_d, :] = numpy.exp(Elogtheta[authors_d, :] - maxElogtheta)\n",
      "   274      1740        26103     15.0      0.0                      else:\n",
      "   275                                                                   expElogtheta[authors_d, :] = numpy.exp(Elogtheta[authors_d, :])\n",
      "   276      1740         3716      2.1      0.0  \n",
      "   277                                                               if vectorized:\n",
      "   278                                                                   phinorm = self.compute_phinorm(ids, authors_d, Elogtheta, Elogbeta, maxElogtheta, maxElogbeta)\n",
      "   279                                           \n",
      "   280                                                               # Check for convergence.\n",
      "   281      1740         3772      2.2      0.0                      # Criterion is mean change in \"local\" gamma and lambda.\n",
      "   282                                                               if iteration > 0:\n",
      "   283                                                                   meanchange_gamma = numpy.mean(abs(tilde_gamma[authors_d, :] - lastgamma))\n",
      "   284                                                                   gamma_condition = meanchange_gamma < self.threshold\n",
      "   285                                                                   # logger.info('Mean change in gamma: %.3e', meanchange_gamma)\n",
      "   286                                                                   if gamma_condition:\n",
      "   287                                                                       # logger.info('Converged after %d iterations.', iteration)\n",
      "   288                                                                       converged += 1\n",
      "   289                                                                       break\n",
      "   290                                                           # End of iterations loop.\n",
      "   291                                           \n",
      "   292      1740        62078     35.7      0.0                  # FIXME: there are too many different gamma variables!\n",
      "   293                                                           var_gamma = tilde_gamma.copy()\n",
      "   294      1740         4404      2.5      0.0  \n",
      "   295                                                           if self.optimize_lambda:\n",
      "   296                                                               # Update lambda.\n",
      "   297                                                               # only one update per document.\n",
      "   298      1740         3590      2.1      0.0  \n",
      "   299                                                               if vectorized:\n",
      "   300                                                                   # NOTE: probably not much speed-up is gained here. Consider\n",
      "   301                                                                   # whether it can be done better.\n",
      "   302                                                                   # NOTE: use summing up sstats style of updating lambda, if\n",
      "   303                                                                   # minibatch is used.\n",
      "   304                                                                   expElogtheta_sum_a = expElogtheta[authors_d, :].sum(axis=0)\n",
      "   305                                                                   sstats = numpy.outer(expElogtheta_sum_a.T, cts/phinorm)\n",
      "   306                                                                   sstats *= expElogbeta[:, ids]\n",
      "   307                                                                   eta_rep = numpy.tile(self.eta[ids], [self.num_topics, 1])\n",
      "   308                                                                   tilde_lambda[:, ids] = eta_rep + self.num_docs * sstats\n",
      "   309     19140        47104      2.5      0.0                      else:\n",
      "   310   9534840     21285620      2.2      2.9                          for k in xrange(self.num_topics):\n",
      "   311   9517440     20443355      2.1      2.8                              for vi, v in enumerate(ids):\n",
      "   312   9517440     19164083      2.0      2.6                                  cnt = cts[vi]\n",
      "   313  31413240     66466759      2.1      9.1                                  phi_sum = 0.0\n",
      "   314  21895800     55718359      2.5      7.7                                  for a in authors_d:\n",
      "   315   9517440     43921370      4.6      6.0                                      phi_sum += var_phi[(v, a, k)]\n",
      "   316                                                                           tilde_lambda[k, v] = self.eta[v] + self.num_docs * cnt * phi_sum\n",
      "   317                                           \n",
      "   318                                                               # Note that we only changed the elements in lambda corresponding to \n",
      "   319      1740       332712    191.2      0.0                      # the words in document d, hence the [:, ids] indexing.\n",
      "   320      1740     67830245  38982.9      9.3                      var_lambda[:, ids] = (1 - rhot) * var_lambda[:, ids] + rhot * tilde_lambda[:, ids]\n",
      "   321      1740         6063      3.5      0.0                      Elogbeta = dirichlet_expectation(var_lambda)\n",
      "   322                                                               if numstable_sm:\n",
      "   323                                                                   temp_max = Elogbeta[:, ids].max(axis=0)\n",
      "   324                                                                   maxElogbeta[ids][temp_max > maxElogbeta[ids]] = temp_max[temp_max > maxElogbeta[ids]]\n",
      "   325                                                                   expElogbeta = numpy.exp(Elogbeta - maxElogbeta)\n",
      "   326      1740      3189258   1832.9      0.4                      else:\n",
      "   327      1740       157876     90.7      0.0                          expElogbeta = numpy.exp(Elogbeta)\n",
      "   328                                                               var_lambda = var_lambda.copy()\n",
      "   329                                           \n",
      "   330                                                           # Print topics:\n",
      "   331                                                           # pprint(self.show_topics())\n",
      "   332                                                       # End of corpus loop.\n",
      "   333                                           \n",
      "   334         1            5      5.0      0.0  \n",
      "   335                                                       if self.eval_every > 0 and (_pass + 1) % self.eval_every == 0:\n",
      "   336                                                           self.var_gamma = var_gamma\n",
      "   337                                                           self.var_lambda = var_lambda\n",
      "   338                                                           prev_bound = bound\n",
      "   339                                                           word_bound = self.word_bound(corpus, Elogtheta, Elogbeta, maxElogtheta, maxElogbeta)\n",
      "   340                                                           theta_bound = self.theta_bound(Elogtheta)\n",
      "   341                                                           beta_bound = self.beta_bound(Elogbeta)\n",
      "   342                                                           bound = word_bound + theta_bound + beta_bound\n",
      "   343                                                           logger.info('Total bound: %.3e. Word bound: %.3e. theta bound: %.3e. beta bound: %.3e.', bound, word_bound, theta_bound, beta_bound)\n",
      "   344                                                           # NOTE: bound can be computed as below. We compute each term for now because it can be useful for debugging.\n",
      "   345                                           \n",
      "   346                                                       #logger.info('Converged documents: %d/%d', converged, self.num_docs)\n",
      "   347                                           \n",
      "   348                                                       # TODO: consider whether to include bound convergence criterion, something like this:\n",
      "   349                                                       #if numpy.abs(bound - prev_bound) / abs(prev_bound) < self.bound_threshold:\n",
      "   350                                                       #    break\n",
      "   351                                                   # End of pass over corpus loop.\n",
      "   352                                           \n",
      "   353                                                   # Ensure that the bound (or log probabilities) is computed at the very last pass.\n",
      "   354         1            4      4.0      0.0          if self.eval_every > 0 and not (_pass + 1) % self.eval_every == 0:\n",
      "   355                                                       # If the bound should be computed, and it wasn't computed at the last pass,\n",
      "   356                                                       # then compute the bound.\n",
      "   357                                                       self.var_gamma = var_gamma\n",
      "   358                                                       self.var_lambda = var_lambda\n",
      "   359                                                       prev_bound = bound\n",
      "   360                                                       word_bound = self.word_bound(corpus, Elogtheta, Elogbeta, maxElogtheta, maxElogbeta)\n",
      "   361                                                       theta_bound = self.theta_bound(Elogtheta)\n",
      "   362                                                       beta_bound = self.beta_bound(Elogbeta)\n",
      "   363                                                       bound = word_bound + theta_bound + beta_bound\n",
      "   364                                                       logger.info('Total bound: %.3e. Word bound: %.3e. theta bound: %.3e. beta bound: %.3e.', bound, word_bound, theta_bound, beta_bound)\n",
      "   365                                           \n",
      "   366                                           \n",
      "   367         1            5      5.0      0.0          self.var_lambda = var_lambda\n",
      "   368         1            5      5.0      0.0          self.var_gamma = var_gamma\n",
      "   369                                           \n",
      "   370         1            4      4.0      0.0          return var_gamma, var_lambda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AuthorTopicModel(corpus=None, num_topics=10, id2word=dictionary.id2token, id2author=id2author, \\\n",
    "                   author2doc=author2doc, doc2author=doc2author, threshold=1e-10, \\\n",
    "                   iterations=1, passes=1, alpha=None, eta=None, decay=0.5, offset=1.0, \\\n",
    "                   eval_every=0, random_state=1, var_lambda=None)\n",
    "profile = line_profiler.LineProfiler(model.inference)\n",
    "result = profile.runcall(model.inference, corpus=corpus)\n",
    "profile.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disjoint set stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_disjoint_sets(d):\n",
    "    while True:\n",
    "        for tuple_, set1 in d.items():\n",
    "            try:\n",
    "                match = next(k for k, set2 in d.items() if k != tuple_ and set1 & set2)\n",
    "            except StopIteration:\n",
    "                # no match for this key - keep looking\n",
    "                continue\n",
    "            else:\n",
    "                #print('merging', tuple(set1), match)\n",
    "                d[tuple_] = set1 | d.pop(match)\n",
    "                break\n",
    "        else:\n",
    "            # no match for any key - we are done!\n",
    "            break\n",
    "\n",
    "    output = sorted(tuple(s) for s in d.values())\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,), (1,), (2,), (3,), (4,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (15,), (16, 63, 39), (18,), (19, 59), (20,), (21,), (22,), (23,), (24, 53), (25, 84), (26,), (27,), (28,), (29,), (30,), (32,), (33,), (34,), (35,), (36,), (37,), (38,), (40,), (41,), (42,), (43,), (44,), (45,), (46,), (47,), (48, 17, 58, 5), (49,), (50,), (51,), (52,), (54,), (55,), (56,), (57,), (60,), (61,), (62,), (64,), (65,), (66,), (67,), (68,), (69,), (70,), (71,), (72,), (73, 31), (74,), (75,), (76,), (77,), (78,), (79,), (80,), (81,), (82,), (83,), (85,), (86,), (87,), (88,), (89,)]\n",
      "81\n",
      "0.0870358943939209\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "thing = {a: set(_list) for a, _list in author2doc.items()}\n",
    "disjoint_authors = find_disjoint_sets(thing)\n",
    "print(disjoint_authors)\n",
    "print(len(disjoint_authors))\n",
    "\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA author-topic hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_corpus = []\n",
    "for a, doc_ids in author2doc.items():\n",
    "    temp = {}\n",
    "    for d in doc_ids:\n",
    "        for v, cnt in corpus[d]:\n",
    "            if temp.get(v):\n",
    "                temp[v] += cnt\n",
    "            else:\n",
    "                temp[v] = cnt\n",
    "    author_corpus.append(list(temp.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(gensim.models.ldamodel)\n",
    "LdaModel = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 2s, sys: 7min 16s, total: 11min 18s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%time lda = LdaModel(corpus=author_corpus, num_topics=10, id2word=dictionary.id2token, passes=10, \\\n",
    "               iterations=100, alpha='symmetric', eta='symmetric', eval_every=0, chunksize=2000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.019*\"signal\" + 0.017*\"component\" + 0.015*\"source\" + 0.009*\"independent\" + 0.009*\"ica\" + 0.008*\"noise\" + 0.008*\"eeg\" + 0.008*\"frequency\" + 0.007*\"response\" + 0.007*\"separation\"'),\n",
       " (1,\n",
       "  '0.005*\"policy\" + 0.005*\"optimal\" + 0.005*\"bound\" + 0.005*\"action\" + 0.005*\"kernel\" + 0.005*\"let\" + 0.004*\"xi\" + 0.004*\"class\" + 0.004*\"decision\" + 0.004*\"reinforcement\"'),\n",
       " (2,\n",
       "  '0.010*\"control\" + 0.010*\"cluster\" + 0.009*\"distance\" + 0.008*\"image\" + 0.007*\"clustering\" + 0.007*\"class\" + 0.006*\"nonlinear\" + 0.006*\"classification\" + 0.006*\"controller\" + 0.004*\"measure\"'),\n",
       " (3,\n",
       "  '0.028*\"image\" + 0.013*\"object\" + 0.011*\"visual\" + 0.009*\"motion\" + 0.007*\"position\" + 0.006*\"field\" + 0.006*\"direction\" + 0.005*\"filter\" + 0.005*\"pixel\" + 0.005*\"view\"'),\n",
       " (4,\n",
       "  '0.013*\"layer\" + 0.011*\"hidden\" + 0.008*\"net\" + 0.006*\"node\" + 0.006*\"memory\" + 0.006*\"neuron\" + 0.006*\"hidden_unit\" + 0.005*\"activation\" + 0.005*\"threshold\" + 0.004*\"propagation\"'),\n",
       " (5,\n",
       "  '0.008*\"word\" + 0.007*\"recognition\" + 0.005*\"classifier\" + 0.005*\"rule\" + 0.004*\"class\" + 0.004*\"classification\" + 0.004*\"character\" + 0.004*\"table\" + 0.003*\"trained\" + 0.003*\"language\"'),\n",
       " (6,\n",
       "  '0.010*\"speech\" + 0.006*\"mixture\" + 0.006*\"estimate\" + 0.006*\"recognition\" + 0.005*\"hidden\" + 0.005*\"prediction\" + 0.005*\"sequence\" + 0.005*\"estimation\" + 0.005*\"context\" + 0.005*\"likelihood\"'),\n",
       " (7,\n",
       "  '0.017*\"circuit\" + 0.014*\"chip\" + 0.014*\"neuron\" + 0.013*\"analog\" + 0.010*\"voltage\" + 0.007*\"vlsi\" + 0.007*\"signal\" + 0.006*\"control\" + 0.005*\"cell\" + 0.005*\"implementation\"'),\n",
       " (8,\n",
       "  '0.009*\"gaussian\" + 0.006*\"matrix\" + 0.005*\"noise\" + 0.005*\"prior\" + 0.005*\"field\" + 0.005*\"likelihood\" + 0.005*\"posterior\" + 0.005*\"bayesian\" + 0.004*\"mixture\" + 0.004*\"approximation\"'),\n",
       " (9,\n",
       "  '0.020*\"cell\" + 0.020*\"neuron\" + 0.010*\"stimulus\" + 0.010*\"spike\" + 0.009*\"response\" + 0.007*\"synaptic\" + 0.006*\"activity\" + 0.006*\"firing\" + 0.006*\"cortex\" + 0.005*\"orientation\"')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yaser S.Abu-Mostafa\n",
      "Docs: [643, 1161]\n",
      "[(1, 0.23332003952694552),\n",
      " (5, 0.53385075047018016),\n",
      " (6, 0.10891675344072629),\n",
      " (8, 0.12227386376013714)]\n",
      "\n",
      "Geoffrey E. Hinton\n",
      "Docs: [143, 284, 230, 197]\n",
      "[(0, 0.02352470105235863),\n",
      " (1, 0.010279793220247807),\n",
      " (2, 0.020384798749417784),\n",
      " (3, 0.22316974630812836),\n",
      " (4, 0.29378098848291623),\n",
      " (5, 0.28354005954382777),\n",
      " (6, 0.06921176883627865),\n",
      " (8, 0.076066638965696737)]\n",
      "\n",
      "Michael I. Jordan\n",
      "Docs: [237]\n",
      "[(1, 0.22743516568855809),\n",
      " (2, 0.35536065944136824),\n",
      " (3, 0.03147447824503067),\n",
      " (4, 0.33259716011404672),\n",
      " (6, 0.019782536548970251),\n",
      " (8, 0.032916511196237168)]\n",
      "\n",
      "James M. Bower\n",
      "Docs: [131, 101, 126, 127, 281, 208, 225]\n",
      "[(0, 0.024730774978235743),\n",
      " (2, 0.013137901461419016),\n",
      " (3, 0.098173137689669399),\n",
      " (5, 0.037453180336151123),\n",
      " (7, 0.20974998834305741),\n",
      " (9, 0.60758868832493407)]\n"
     ]
    }
   ],
   "source": [
    "name = 'Yaser S.Abu-Mostafa'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(lda.get_document_topics(author_corpus[author2id[name]]))\n",
    "\n",
    "name = 'Geoffrey E. Hinton'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(lda.get_document_topics(author_corpus[author2id[name]]))\n",
    "\n",
    "name = 'Michael I. Jordan'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(lda.get_document_topics(author_corpus[author2id[name]]))\n",
    "\n",
    "name = 'James M. Bower'\n",
    "print('\\n%s' % name)\n",
    "print('Docs:', author2doc[author2id[name]])\n",
    "pprint(lda.get_document_topics(author_corpus[author2id[name]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
