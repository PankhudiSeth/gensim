{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Mover's Distance\n",
    "\n",
    "> **Note:**\n",
    ">\n",
    "> Almost everything in this notebook is subject to change at the moment.\n",
    "\n",
    "Word Mover's Distance (WMD) is a new and exciting method in machine learning that helps us measure the similarity of two sentences. WMD can be used for document retrieval, and has been shown to outperform many of the current state-of-the-art methods in $k$-nearest neighbors classification [1]. As we shall see, the benefit of WMD is that we can accurately assess the similarity of two documents, even when they have no words in common.\n",
    "\n",
    "WMD uses word2vec vector embeddings [2] of words (read about word2vec in Gensim [here](http://rare-technologies.com/deep-learning-with-word2vec-and-gensim/) and [here](http://rare-technologies.com/word2vec-tutorial/)).\n",
    "\n",
    "WMD is illustrated below for two very similar sentences. The sentences have no words in common, but by matching the relevant words, WMD is able to accurately measure the similarity between the two sentences. The method also uses the bag-of-words representation of the documents (simply put, the word's frequencies in the documents), noted as $d$ in the figure below. The intution behind the method is that we find the minimum \"traveling distance\" between documents, the most efficient way to \"move\" the distribution of document 1 to the distribution of document 2.\n",
    "\n",
    "<img src='https://vene.ro/images/wmd-obama.png' height='600' width='600'>\n",
    "\n",
    "\n",
    "This method was introduced in the article \"From Word Embeddings To Document Distances\" by Matt Kusner et al. ([link to PDF](http://jmlr.org/proceedings/papers/v37/kusnerb15.pdf)). It is inspired by the \"Earth Mover's Distance\", and employs a solver of the \"transportation problem\".\n",
    "\n",
    "In this tutorial, we will learn how to use Gensim's WMD functionality, which consists of the `wmdistance` method for distance computation, and the `WmdSimilarity` class for corpus based similarity queries.\n",
    "\n",
    "> **Note**:\n",
    ">\n",
    "> If you use this software, please consider citing the following papers:\n",
    ">\n",
    "> Ofir Pele and Michael Werman, \"A linear time histogram metric for improved SIFT matching\".\n",
    "> \n",
    "> Ofir Pele and Michael Werman, \"Fast and robust earth mover's distances\".\n",
    ">\n",
    "> Matt Kusner et al. \"From Word Embeddings To Document Distances\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Running this notebook:**\n",
    ">\n",
    "> You can download this [iPython Notebook](http://ipython.org/notebook.html) (**FIXME:** how?), and run it on your own computer, provided you have installed Gensim and NLTK, and downloaded the necessary data.\n",
    ">\n",
    "> The notebook was run on an Ubuntu machine with an Intel core i7-4770 CPU 3.40GHz (8 cores) and 32 GB memory. Running the entire notebook on this machine takes about 5 minutes. (**TODO: update this when code is optimized**).\n",
    "\n",
    "## Using WMD\n",
    "\n",
    "To use WMD, we need some word embeddings first of all. You could train a word2vec (see tutorial [here](http://rare-technologies.com/word2vec-tutorial/)) model on some corpus, but we will start by download some pre-trained word2vec embeddings. Download these embeddings [here](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit). Training your own embeddings can be beneficial, but to simplify this tutorial, we will be using pre-trained embeddings at first.\n",
    "\n",
    "Let's take some sentences to compute the distance between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "start_nb = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize logging.\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "\n",
    "sentence1 = 'Obama speaks to the media in Illinois'\n",
    "sentence2 = 'The president greets the press in Chicago'\n",
    "sentence1 = sentence1.lower().split()\n",
    "sentence2 = sentence2.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These sentences have very similar content, and as such the WMD should be low. Before we compute the WMD, we want to remove stopwords (\"the\", \"to\", etc.), as these do not contribute a lot to the information in the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/olavur/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import and download stopwords from NLTK.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "download('stopwords')  # Download stopwords list.\n",
    "\n",
    "# Remove stopwords.\n",
    "stop_words = stopwords.words('english')\n",
    "sentence1 = [w for w in sentence1 if w not in stop_words]\n",
    "sentence2 = [w for w in sentence2 if w not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as mentioned earlier, we will be using some downloaded pre-trained embeddings. We load these into a Gensim Word2Vec model class. Note that the embeddings we have chosen here require a lot of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell took 81.989456 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load_word2vec_format('/data/w2v_googlenews/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "print 'Cell took %f seconds to run.' %(time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's compute WMD using the `wmdistance` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance = 1.0175\n"
     ]
    }
   ],
   "source": [
    "distance = model.wmdistance(sentence1, sentence2)\n",
    "print 'distance = %.4f' % distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same thing with two completely unrelated sentences. Notice that the distance is larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance = 1.3604\n"
     ]
    }
   ],
   "source": [
    "sentence1 = 'Obama speaks to the media in Illinois'\n",
    "sentence3 = 'Oranges are my favorite type of fruit'\n",
    "sentence1 = sentence1.lower().split()\n",
    "sentence3 = sentence3.lower().split()\n",
    "sentence1 = [w for w in sentence1 if w not in stop_words]\n",
    "sentence3 = [w for w in sentence3 if w not in stop_words]\n",
    "\n",
    "distance = model.wmdistance(sentence1, sentence3)\n",
    "print 'distance = %.4f' % distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing word2vec vectors\n",
    "\n",
    "When using the `wmdistance` method, it is beneficial to normalize the word2vec vectors first, so they all have length equal to 1. To do this, simply call `model.init_sims(replace=True)` and Gensim will take care of that for you.\n",
    "\n",
    "The reason it is beneficial to use normalized vectors is that word2vec is optimized for cosine distance (see [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity)), which measures the angle between vectors, but WMD uses Euclidean distance. The Euclidean distance between two vectors might be large because their lengths differ, but the cosine distance is small because the angle between them is small; we can mitigate some of this by normalizing the vectors.\n",
    "\n",
    "Note that normalizing the vectors can take some time, especially if you have a large vocabulary and/or large vectors.\n",
    "\n",
    "Usage is illustrated in the example below. It just so happens that the vectors we have downloaded are already normalized, so it won't do any difference in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell took 11.987278 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "# Normalizing word2vec vectors.\n",
    "start = time()\n",
    "\n",
    "model.init_sims(replace=True)  # Normalizes the vectors in the word2vec class.\n",
    "\n",
    "distance = model.wmdistance(sentence1, sentence2)  # Compute WMD as normal.\n",
    "\n",
    "print 'Cell took %f seconds to run.' %(time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-computing distance matrix\n",
    "\n",
    "If you are computing distances between a lot of documents (as we will be doing in the next section), we can speed up the process by pre-computing the distances between all the words in the vocabulary.\n",
    "\n",
    "**FIXME:** finish this section when pre-computing distance matrix is implented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity queries\n",
    "\n",
    "You can use WMD to get the most similar documents to a query, using the `WmdSimilarity` class. Its interface is similar to what is described in the [Similarity Queries](https://radimrehurek.com/gensim/tut3.html) Gensim tutorial.\n",
    "\n",
    "> **Important note:**\n",
    ">\n",
    "> WMD is a measure of *distance*, which is in fact the opposite of similarity. The similarities in `WmdSimilarity` are simply the *negative distance*. Be careful not to confuse distances and similarities.\n",
    "\n",
    "Let's try similarity queries using some real world data. For that we'll be using Yelp reviews, available at http://www.yelp.com/dataset_challenge. Specifically, we will be using reviews of a single restaurant.\n",
    "\n",
    "This time around, we are going to train the Word2Vec embeddings on the data ourselves. One restaurant is not enough to train Word2Vec properly, so we use 6 restaurants for that, but only run queries against one of them. More information about the data is in the **Yelp data** section.\n",
    "\n",
    "Below a JSON file with Yelp reviews is read line by line, the text is extracted, tokenized, and stopwords and punctuation are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/olavur/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "\n",
      "Cell took 38.429271 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "import json\n",
    "from nltk import word_tokenize\n",
    "download('punkt')  # Download data for tokenizer.\n",
    "\n",
    "# Business IDs of some restaurants.\n",
    "ids = ['4bEjOyTaDG24SY5TxsaUNQ', '2e2e7WgqU1BnpxmQL5jbfw', 'zt1TpTuJ6y9n551sw9TaEg',\n",
    "      'Xhg93cMdemu5pAMkDoEdtQ', 'sIyHTizqAiGu12XMLX3N3g', 'YNQgak-ZLtYJQxlDwN-qIg']\n",
    "\n",
    "# Load some text data.\n",
    "w2v_corpus = []  # Documents to train word2vec on.\n",
    "wmd_corpus = []  # Documents to run queries against.\n",
    "documents = []  # wmd_corpus, with no pre-processing (so we can print the original documents).\n",
    "with open('/home/olavur/yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_review.json') as data_file:\n",
    "    for line in data_file:\n",
    "        json_line = json.loads(line)\n",
    "        \n",
    "        if json_line['business_id'] not in ids:\n",
    "            # Not interested in this business.\n",
    "            continue\n",
    "        \n",
    "        # Pre-process document.\n",
    "        text = json_line['text'].lower()  # Lower the text.\n",
    "        text = word_tokenize(text)  # Split into words.\n",
    "        text = [w for w in text if not w in stop_words]  # Remove stopwords.\n",
    "        text = [w for w in text if w.isalpha()]  # Remove numbers and punctuation.\n",
    "        \n",
    "        # Add to corpus for training Word2Vec.\n",
    "        w2v_corpus.append(text)\n",
    "        \n",
    "        if json_line['business_id'] == ids[0]:\n",
    "            # Only use this restaurant in corpus for WmdSimilarity.\n",
    "            wmd_corpus.append(text)\n",
    "            documents.append(json_line['text'])\n",
    "\n",
    "print '\\nCell took %f seconds to run.' %(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train Word2Vec on all the restaurants.\n",
    "model = Word2Vec(w2v_corpus, workers=7, size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to initialize the similarity class with a corpus and a word2vec model (which provides the embeddings and the `wmdistance` method itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell took 158.570173 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "from gensim.similarities import WmdSimilarity\n",
    "instance = WmdSimilarity(wmd_corpus, model, num_best=10)\n",
    "\n",
    "print 'Cell took %f seconds to run.' %(time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `num_best` parameter decides how many results the queries return. Now let's try making a query. The output is a list of indeces and similarities of documents in the corpus, sorted by similarity. Note that the output format is slightly different when `num_best` is `None` (i.e. not assigned).\n",
    "\n",
    "The query below is taken directly from one of the reviews in the corpus. Let's see if there are other reviews that are similar to this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent = 'Very good, you should seat outdoor.'\n",
    "\n",
    "# Pre-process query.\n",
    "query = sent.lower()  # Lower the text.\n",
    "query = word_tokenize(query)  # Split into words.\n",
    "query = [w for w in query if not w in stop_words]  # Remove stopwords.\n",
    "query = [w for w in query if w.isalpha()]  # Remove numbers and punctuation.\n",
    "\n",
    "sims = instance[query]  # A query is simply a \"look-up\" in the similarity class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query and the most similar documents, together with the similarities, are printed below. We see that the retrieved documents are discussing the same thing as the query, although using different words. The query talks about getting a seat \"outdoor\", while the results talk about sitting \"outside\", and one of them says the restaurant has a \"nice view\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "Very good, you should seat outdoor.\n",
      "\n",
      "sim = -0.7492\n",
      "It's a great place if you can sit outside in good weather.\n",
      "\n",
      "sim = -0.7537\n",
      "It was good I like the outside\n",
      "\n",
      "sim = -0.8371\n",
      "nice view, good service\n"
     ]
    }
   ],
   "source": [
    "# Print the query and the retrieved documents, together with their similarities.\n",
    "print 'Query:'\n",
    "print sent\n",
    "for i in range(3):\n",
    "    print\n",
    "    print 'sim = %.4f' % sims[i][1]\n",
    "    print documents[sims[i][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a different query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "I felt that the prices were extremely reasonable for the Strip\n",
      "\n",
      "sim = -0.7081\n",
      "Reasonable prices. Makes for a nice dinner out in the town.\n",
      "\n",
      "sim = -0.8267\n",
      "Exceptional food at reasonable prices.  Reservations are a must.\n",
      "\n",
      "sim = -0.8377\n",
      "Had lunch here, food price was very reasonable for vegas and the atmosphere was great.\n"
     ]
    }
   ],
   "source": [
    "sent = 'I felt that the prices were extremely reasonable for the Strip'\n",
    "\n",
    "# Pre-process query.\n",
    "query = sent.lower()  # Lower the text.\n",
    "query = word_tokenize(query)  # Split into words.\n",
    "query = [w for w in query if not w in stop_words]  # Remove stopwords.\n",
    "query = [w for w in query if w.isalpha()]  # Remove numbers and punctuation.\n",
    "\n",
    "sims = instance[query]  # A query is simply a \"look-up\" in the similarity class.\n",
    "\n",
    "print 'Query:'\n",
    "print sent\n",
    "for i in range(3):\n",
    "    print\n",
    "    print 'sim = %.4f' % sims[i][1]\n",
    "    print documents[sims[i][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time around, the results are more straight forward; the retrieved documents basically contain the same words as the query.\n",
    "\n",
    "### Yelp data\n",
    "\n",
    "As mentioned previously, we used reviews of 6 different restaurants to train Word2Vec, and then ran queries against one of these restaurants. The restaurants we chose were those with the highest number of reviews in the Yelp dataset.\n",
    "\n",
    "The corpus we trained Word2Vec on has 18957 documents (reviews), and the corpus we used for `WmdSimilarity` has 4137 documents.\n",
    "\n",
    "Below is a plot with a histogram of document lengths and includes the average document length as well. Note that these are the pre-processed documents, meaning stopwords are removed, punctuation is removed, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAGVCAYAAABn+SKpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa89e888c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Document lengths.\n",
    "lens = [len(doc) for doc in wmd_corpus]\n",
    "\n",
    "# Plot.\n",
    "plt.rc('figure', figsize=(8,6))\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', color_cycle=('#377eb8','#e41a1c','#4daf4a',\n",
    "                            '#984ea3','#ff7f00','#ffff33'))\n",
    "# Histogram.\n",
    "plt.hist(lens, bins=20)\n",
    "plt.hold(True)\n",
    "# Average length.\n",
    "avg_len = sum(lens) / float(len(lens))\n",
    "plt.axvline(avg_len, color='#e41a1c')\n",
    "plt.hold(False)\n",
    "plt.title('Histogram of document lengths.')\n",
    "plt.xlabel('Length')\n",
    "plt.text(100, 800, 'mean = %.2f' % avg_len)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Matt Kusner et al. *From Embeddings To Document Distances*, 2015.\n",
    "* Thomas Mikolov et al. *Efficient Estimation of Word Representations in Vector Space*, 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook took 303.515293 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "print 'Notebook took %f seconds to run.' %(time() - start_nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
